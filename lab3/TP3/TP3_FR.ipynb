{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF 8215 - Intelligence artif.: méthodes et algorithmes \n",
    "## Automne 2018 - TP3 - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date de rendu: 6 Décembre**\n",
    "\n",
    "**Fichiers à rendre:**\n",
    "    * TP3_FR.ipynb complété\n",
    "    * SoftmaxClassifier.py complété\n",
    "    * test_prediction.csv le fichier de résultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Le but de ce TP est de vous donner un aperçu du déroulement général d'un projet de machine learning tout en vous familiarisant avec des librairies python adaptées.\n",
    "\n",
    "\n",
    "Dans la première partie, vous implémenterez un algorithme de classification multiclasse appelé **softmax regression** à l'aide uniquement de la bibliothèque **numpy** et l'intégrerez à la bibliothèque **scikit-learn**.\n",
    "\n",
    "Dans la deuxième partie, vous prendrez connaissance du **dataset** utilisé pour ce projet. Et vous serez amenés à effectuer le **preprocessing** de ces données pour qu'elles soient utilisables dans les algorithmes de machine learning classiques. Vous utiliserez les bibliothèques **pandas** et **scikit-learn**.\n",
    "\n",
    "Enfin, dans la troisième partie, vous comparerez l'efficacité du modèle que vous avez implémenté avec d'autres modèles déjà implémentés dans **sklearn**. Puis vous tenterez d'améliorer les performances de l'algorithme sélectionné.\n",
    "\n",
    "Pour enfin soumettre vos résultats sur la plateforme **kaggle**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Pour installer **pandas** et **scikit-learn** le plus simple est de télécharger et d'installer **Anaconda** qui regroupe les packages les plus utilisés pour le calcul scientifique et la science des données.\n",
    "\n",
    "Vous trouverez la distribution ici : https://www.anaconda.com/download/#linux .\n",
    "\n",
    "Assurez-vous d'avoir la version **20.0** de **scikit-learn**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 1: Compétition (2 points)\n",
    "\n",
    "Quand vous aurez terminé le TP, vous pourrez soumettre vos prédictions sur **kaggle**, vous obtiendrez votre performance en terme de **log loss**.\n",
    "Vous pouvez ensuite me communiquer ce résultat par mail (laurent.boucaud@polymtl.ca) et me joindre votre fichier de prédiction sur l'ensemble de test(pour vérification).\n",
    "\n",
    "Une conversation dans le forum sera créée pour tenir à jour le meilleur score obtenu par une des équipes du cours.\n",
    "\n",
    "Tant qu'aucun forum n'est créé, **ne m'envoyez pas vos performances si elles sont supérieures à 0.8 de log loss**.\n",
    "\n",
    "Une fois le premier meilleur score affiché dans le forum, **ne me communiquez vos résultats que si votre log loss est inférieure au précédent meilleur score**.\n",
    "\n",
    "Le nombre de points obtenus sera proportionnel au classement des équipes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Softmax Regression (10 points)\n",
    "\n",
    "Dans cette partie vous implémenterez **softmax regression** la variante de **logistic regression** qui permet d'effectuer de la classification pour un nombre de classe supérieur à 2.\n",
    "\n",
    "Le code à compléter se trouve dans le fichier **SoftmaxClassifier.py**. \n",
    "\n",
    "**Pour cet exercice, la contrainte est d'utiliser uniquement la bibliothèque numpy**\n",
    "\n",
    "## Encapsulation avec sklearn\n",
    "\n",
    "La classe **SoftmaxClassifier** hérite des classes **BaseEstimator** et **ClassifierMixin** de **scikit-learn** ce qui nous permettra d'utiliser facilement avec notre classifier les outils fournis par scikit-learn dans la suite du TP.\n",
    "\n",
    "Pour la compatibilité, le classifier implémente obligatoirement les méthodes:\n",
    "\n",
    "* **fit**: responsable de l'entraînement du modèle\n",
    "* **predict_proba**: permet de prédire la probabilité de chaque classe pour chaque exemple du dataset fourni.\n",
    "* **predict**: permet de prédire la classe pour chaque exemple du dataset fourni.\n",
    "* **score**: permet de quantifier l'écart entre les classes prédites et les classes réelles pour le dataset fourni\n",
    "\n",
    "\n",
    "## Train/Test set:\n",
    "\n",
    "Quand on veut tester les performances de l'apprentissage d'un algorithme de machine learning, on **ne le teste pas sur les données utilisées pour l'apprentissage**.\n",
    "\n",
    "En effet, ce qui nous intéresse c'est que notre algorithme soit **capable de généraliser** ses prédictions à des données qu'il n'a **jamais vu**.\n",
    "\n",
    "Pour illustrer, si on teste un algorithme sur les données d'entrainement, on teste sa capacité à **apprendre par coeur** le dataset et non à **généraliser**.\n",
    "\n",
    "Par conséquent, quand on reçoit un nouveau dataset, la première chose à faire et de le **diviser en deux parties**: un ensemble d'**entraînement** (**70-80%** du dataset) et un ensemble de **test**(**20-30%** du dataset).\n",
    "\n",
    "Tous les algorithmes de **traitement des données** et d'apprentissage devront être appris uniquement sur l'ensemble d'entraînement et appliqués ensuite sur l'ensemble de test.\n",
    "\n",
    "Cela garantit l'absence de connaissances préalables de l'ensemble de test lors de l'entrainement.\n",
    "\n",
    "## Gradient descent\n",
    "\n",
    "La descente de gradient est un algorithme qui permet trouver la solution optimale d'un certains nombre de problèmes. Le principe est le suivant: on définit une **fonction de coût J**  qui caractérise le problème.\n",
    "Cette fonction dépend d'un ensemble de **paramètres $\\theta$ **. La descente de gradient cherche à **minimiser** la fonction de coût en **modifiant itérativement** les paramètres.\n",
    "\n",
    "### Gradient\n",
    "\n",
    "Le gradient de la fonction de coûts pour un $\\theta$ donné, correspond à la direction dans laquelle il faut modifier $\\theta$ pour réduire la valeur de la fonction de coût. \n",
    "\n",
    "La fonction de coût est minimale quand le gradient est nul.\n",
    "\n",
    "Concrètement, on initialize $\\theta$ aléatoirement, et on effectue à chaque itération un pas pour réduire la fonction de coût jusqu'à convergence de l'algorithme à un minimum.\n",
    "\n",
    "### Learning rate\n",
    "\n",
    "Le taux d'apprentissage correspond à la taille du pas que l'on va effectuer dans la direction du gradient.\n",
    "Plus il est grand, plus la convergence est rapide mais il y a un risque que l'algorithme diverge.\n",
    "\n",
    "Plus il est petit, plus la convergence est lente.\n",
    "\n",
    "### Batch gradient descent\n",
    "\n",
    "Il existe plusieurs algorithmes de descente de gradient. Nous utiliserons Batch gradient descent.\n",
    "\n",
    "Dans cet algorithme, avant de mettre à jour $\\theta$, on calcule les gradients sur l'ensemble des exemples d'entraînement.\n",
    "\n",
    "### Epoch\n",
    "\n",
    "Il s'agit d'un pas de la descente de gradient, soit une unique mise à jour de gradient.\n",
    "\n",
    "### Bias/Variance tradeoff\n",
    "\n",
    "Lorsqu'on entraine un algorithme de machine learning on cherche un équilibre entre **biais** et **variance**.\n",
    "\n",
    "Un modèle avec un **biais fort**, est un modèle qui est **trop simple** pour la structure donnée considérée (modèle linéaire pour données quadratiques), cela limite la capacité du modèle à généraliser. On appelle aussi le biais **underfitting**.\n",
    "\n",
    "Un modèle avec une **variance élevée** signifie qu'il est sensible aux petites variations dans les données d'entrainement, cela correspond à l'**overfitting**, c'est-à-dire que le modèle est trop proche de la structure de l'ensemble d'entrainement ce qui **limite sa capacité à généraliser**.\n",
    "\n",
    "Un modèle avec un **biais important** aura une **mauvaise performance** sur l'ensemble d'**entraînement**.\n",
    "Un modèle avec une **variance importante** aura une performance bien **moins bonne** sur l'ensemble de **test** que sur l'ensemble d'**entrainement**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot-encoding\n",
    "\n",
    "En machine learning pour représenter un vecteur de données catégoriques, on utilise le one-hot encoding.\n",
    "\n",
    "Pour un vecteur comportant 5 exemples et 3 catégories différentes, on le représente sous forme d'une matrice de taille 5 par 3. Cette matrice est entièrement remplie de 0 sauf à l'indice correspondant au numéro de la classe pour chaque exemple.\n",
    "\n",
    "\n",
    "Par exemple\n",
    "$ y = \\left(\\begin{array}{cc} \n",
    "1 \\\\\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "3 \\\\\n",
    "2 \\\\\n",
    "\\end{array}\\right) $\n",
    "\n",
    "devient:\n",
    "\n",
    "$ yohe =  \\left(\\begin{array}{cc} \n",
    "1. & 0. & 0.\\\\\n",
    "1. & 0. & 0.\\\\\n",
    "0. & 1. & 0.\\\\\n",
    "0. & 0. & 1.\\\\\n",
    "0. & 1. & 0.\\\\\n",
    "\\end{array}\\right) $\n",
    "\n",
    "\n",
    "#### Question 1 (1 point)\n",
    "Implémentez  la fonction  **_one_hot**  dans SoftmaxClassifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-71-cc2aca057fb2>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-71-cc2aca057fb2>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    for value in y:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "one_hot = []\n",
    "        for value in y:\n",
    "            sub_y = [0 for _ in range(max(y))]\n",
    "            sub_y[value] = 1\n",
    "            one_hot.append(sub_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de poids\n",
    "\n",
    "Soit $ X_{m * n} $ la matrice d'exemple et $ \\Theta _{n*K} $ la matrice de poids avec:\n",
    "\n",
    "* **m** le nombre d'exemples\n",
    "* **n** le nombre de features\n",
    "* **k** le nombre de classes\n",
    "\n",
    "Il est d'usage d'ajouter une colonne supplémentaire à X, cette colonne est remplie de 1. Pour prendre en compte ce changement, il faut rajouter une ligne à la matrice $\\Theta$.\n",
    "\n",
    "On obtient X_bias$_{m*(n+1)}$ et $ \\Theta _{(n+1)*K} $\n",
    "\n",
    "\n",
    "Intuitivement, à chaque classe K est associée une colonne de $\\theta$.\n",
    "\n",
    "On note $\\theta_k$ le vecteur de dimension n+1 la colonne de poids associée à la prédiction de la classe k.\n",
    "\n",
    "$\\Theta$ = [$\\theta_0$,$\\theta_1$... $\\theta_k$ ... $\\theta_n$ ]\n",
    "\n",
    "Ainsi $ z = x * \\Theta $ donne un vecteur de dimension K qui correspond aux **logits** associés à x pour chacune des classes.\n",
    "\n",
    "#### Question 2 (1 point)\n",
    "Dans la fonction  **fit**  dans SoftmaxClassifier.py instanciez X_bias et initialisez $\\Theta$ aléatoirement. (ligne 74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.71518363e-01 5.16278174e-01 1.64931680e-01 1.96279532e-01\n",
      "  3.29673389e-01 5.16058695e-01 1.44360226e-02 4.14051013e-01\n",
      "  1.54760879e-02 7.46039268e-01 9.00172133e-01 1.64314198e-01\n",
      "  8.08195075e-01 7.83501049e-01 7.18779668e-01 5.75877260e-01\n",
      "  1.10942835e-01 1.42982705e-02 5.22468831e-01 2.97574737e-01\n",
      "  3.63932428e-01 6.96290270e-01 9.80667911e-01 2.52194398e-01]\n",
      " [8.82343839e-01 8.17307911e-01 2.15803422e-01 6.37128535e-01\n",
      "  7.52145159e-01 8.19084590e-01 7.00190911e-01 4.81755621e-01\n",
      "  2.13641023e-01 1.47633491e-01 1.53720378e-01 2.66110684e-01\n",
      "  9.66933167e-01 4.76827374e-01 5.34919452e-01 8.27399783e-01\n",
      "  2.41159156e-01 3.80867867e-01 2.39512270e-01 6.65231904e-01\n",
      "  6.66016788e-01 7.64372376e-01 2.78288993e-01 8.44222247e-01]\n",
      " [2.77743886e-01 7.89662153e-01 7.00962108e-01 1.58566511e-01\n",
      "  9.97460401e-01 3.03418204e-01 3.58317407e-01 4.84717343e-01\n",
      "  1.12390724e-01 4.08310299e-01 5.74501273e-01 8.79092903e-01\n",
      "  2.29928124e-01 5.70274872e-01 9.56463789e-01 8.70533969e-01\n",
      "  4.61473998e-01 3.75155272e-01 8.68337797e-01 9.38300707e-01\n",
      "  1.83488416e-01 6.45471177e-01 2.18122503e-01 9.58422754e-01]\n",
      " [1.20513051e-02 8.25775816e-01 7.93126629e-01 5.08038129e-01\n",
      "  3.64199673e-01 6.60476857e-01 1.39391948e-01 9.42800239e-01\n",
      "  3.10474480e-01 5.11016311e-01 5.55143072e-01 7.33016801e-01\n",
      "  1.16200680e-01 2.74164237e-02 9.69803040e-01 6.32489816e-01\n",
      "  9.14732851e-02 2.63514580e-01 6.50730607e-01 1.15856037e-01\n",
      "  5.65821804e-01 7.68514395e-01 6.74308225e-01 8.69814007e-01]\n",
      " [7.15382808e-01 4.84478702e-01 7.09985376e-01 7.66125249e-01\n",
      "  8.50119454e-01 2.78047047e-01 2.46354598e-01 4.56782375e-02\n",
      "  4.65088716e-01 5.50107554e-01 5.94756373e-01 4.43769709e-02\n",
      "  1.19985983e-01 7.53409223e-01 8.44839550e-01 3.49345523e-01\n",
      "  7.50911214e-01 6.74283687e-01 8.78693256e-01 9.24740056e-01\n",
      "  2.36761297e-01 4.85159369e-01 1.04295510e-01 6.49512110e-02]\n",
      " [9.92633335e-01 3.62250539e-01 9.75999917e-01 9.69426053e-01\n",
      "  8.57198884e-02 1.97247583e-01 6.82576691e-01 8.14134170e-01\n",
      "  3.02653602e-01 8.13922688e-01 4.85071082e-01 8.30830639e-01\n",
      "  6.15480494e-01 7.45713986e-01 1.64563405e-01 3.56980300e-01\n",
      "  9.78473189e-01 3.59935735e-01 4.81431575e-01 3.02498863e-01\n",
      "  1.27296728e-04 5.19916511e-01 4.05436139e-01 6.18116890e-01]\n",
      " [7.20894896e-01 8.44875485e-01 1.00431285e-01 6.98165939e-01\n",
      "  4.96102951e-01 3.18211866e-01 9.07535036e-01 8.57691299e-01\n",
      "  1.23241294e-01 8.09119922e-01 9.42420510e-01 9.53118747e-02\n",
      "  2.64783280e-01 6.99556351e-01 6.35618263e-01 8.09669127e-01\n",
      "  7.79246726e-01 8.28721190e-02 4.06849526e-01 6.90738755e-01\n",
      "  3.07047414e-01 3.08586306e-01 5.85350006e-01 8.88337760e-01]\n",
      " [6.04691491e-02 8.79404017e-01 3.60309425e-01 3.85623436e-01\n",
      "  1.26767582e-01 6.58275931e-01 6.76698602e-01 2.70675400e-03\n",
      "  3.47883269e-01 1.49651871e-01 6.41840883e-01 3.58474786e-01\n",
      "  5.16006165e-01 6.25832105e-01 5.96315338e-02 1.19568603e-01\n",
      "  4.80335804e-01 9.07653758e-01 7.79010005e-01 8.01853150e-02\n",
      "  6.72919168e-02 5.02975870e-01 3.93488455e-01 5.80145318e-01]\n",
      " [6.23541721e-01 4.99104482e-01 2.75845642e-01 3.99577533e-01\n",
      "  4.38104927e-01 2.63804942e-01 9.43486356e-02 2.54796866e-01\n",
      "  5.54110757e-01 9.10281930e-02 4.89522477e-01 7.21088044e-01\n",
      "  5.35102889e-01 9.37790764e-01 3.72636368e-01 5.26168370e-01\n",
      "  1.94744274e-01 8.30652627e-01 1.96438085e-01 9.56890981e-01\n",
      "  8.85381534e-02 5.23501357e-01 4.72537978e-01 8.33372716e-02]]\n"
     ]
    }
   ],
   "source": [
    "theta = np.random.rand(8 + 1, 24)\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "\n",
    "On veut convertir le vecteur de logits **z** obtenu dans la partie précédente, en un **vecteur de probabilité**.\n",
    "\n",
    "Pour cela on définit la **fonction softmax**:\n",
    "\n",
    "$$ \\hat{p_x}^k = softmax(z)_k = \\frac{exp(z_k)}{\\sum_{\\substack{1<j<K}} exp(z_j)} $$\n",
    "\n",
    "Intuitivement, pour un logit de z, $z_k$, on prend l'exponentielle de cette valeur et on la divise par la somme des exponentielles de chaque logit du vecteur **z**. On obtient  $\\hat{p_x}^k$ la probabilité que l'exemple **x** appartienne à la classe **k**.\n",
    "\n",
    "On réitère l'opération pour chaque logit du vecteur **z**. \n",
    "\n",
    "On obtient ainsi un vecteur de probabilités $\\hat{p_x}$ pour un exemple **x**. \n",
    "\n",
    "La division permet de rendre la somme des termes du vecteur $\\hat{p_x}$ égale à 1 ce qui est indispensable dans le cadre des probabilités.\n",
    "\n",
    "#### Question 3 (1 point)\n",
    "Implémentez  la fonction  **_softmax**  dans SoftmaxClassifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4 (1 point)\n",
    "En utilisant la fonction **_softmax** de la question 3, implémentez  les fonctions  **predict_proba** et **predict**  dans SoftmaxClassifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de coût Log loss\n",
    "\n",
    "Soit la fonction de coût log loss (ou cross entropy):\n",
    "\n",
    "$$ J( \\Theta) = \\frac{-1}{m}\\sum_{\\substack{1<i<m}} \\sum_{\\substack{1<k<K}} y_k^i log( \\hat{p_k}^i ) $$\n",
    "\n",
    "avec:\n",
    "* **K** le nombre de classes\n",
    "* **m** le nombre d'exemples dans les données\n",
    "* $ \\hat{p_k}^i  $  la probabilité que l'exemple i soit de la classe k\n",
    "* $y_k^i$ vaut 1 si la classe cible de l'exemple i est k, 0 sinon\n",
    "\n",
    "**Détail d'implémentation:** La fonction n'est pas définie pour des valeurs de probabilité de 0. ou 1., il faut donc s'assurer que étant donné $\\epsilon$, les probabilités sont comprises dans [$\\epsilon$, 1. - $\\epsilon$].\n",
    "#### Question 5 (1 point)\n",
    "Implémentez  la fonction  **_cost_function**  dans SoftmaxClassifier.py en prenant en compte le **détail d'implémentation** (variable self.eps) et utilisez-la pour calculer la variable **loss** dans la fonction **fit** (ligne 84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient de la fonction de coût\n",
    "\n",
    "Le **gradient de J** par rapport à la classe k (par rapport à $\\theta_k$) est :\n",
    "\n",
    "\n",
    "$$ \\Delta_{\\theta_k}J( \\Theta) = \\frac{1}{m} \\sum_{\\substack{1<i<m}}( \\hat{p_k}^i - y_k^i)x^i  $$\n",
    "\n",
    "avec:\n",
    "* **K** le nombre de classes\n",
    "* **m** le nombre d'exemples dans les données\n",
    "* $ \\hat{p_k}^i  $  la probabilité que l'exemple i soit de la classe k\n",
    "* $y_k^i$ vaut 1 si la classe cible de l'exemple i est k, 0 sinon\n",
    "\n",
    "Sous **forme matricielle**, on peut écrire le **gradient de J par rapport à $\\Theta$**:\n",
    "$$ \\Delta_J( \\Theta) = \\frac{1}{m} X_{bias}^T *( \\hat{p} - y_{ohe}) $$\n",
    "\n",
    "avec:\n",
    "* $\\hat{p}$ la matrice de probabilité prédite pour chaque example et pour chaque classe\n",
    "* $y_{ohe}$ la version one-hot de y\n",
    "* $X_{bias}^T$  la matrice transposée de $X_{bias}$\n",
    "* **\\*** le produit matriciel\n",
    "\n",
    "#### Question 6 (1 point)\n",
    "Implémentez  la fonction  **_get_gradient**  dans SoftmaxClassifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise à jour des poids\n",
    "\n",
    "Quand le gradient a été calculé, il faut mettre à jour les poids avec ces gradients.\n",
    "\n",
    "$$ \\Theta  = \\Theta - \\gamma \\Delta J( \\Theta) $$\n",
    "\n",
    "\n",
    "avec:\n",
    "* $\\Theta$ la matrice de poids\n",
    "* $\\gamma$  le taux d'apprentissage\n",
    "* $\\Delta J( \\Theta)$ le gradient de $J( \\Theta)$ selon $\\Theta$\n",
    "\n",
    "#### Question 7 (1 point)\n",
    "Mettez à jour la variable **self.theta_** dans la fonction **fit**  dans SoftmaxClassifier.py (ligne 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "Pour limiter l'**overfitting**, on utilise la régularisation, il s'agit d'ajouter un terme à la fonction de coût $J( \\Theta)$.\n",
    "\n",
    "Ce terme va ajouter des contraintes sur les poids du modèle lors de l'entrainement.\n",
    "Nous allons utiliser la régularisation **L2** :\n",
    "\n",
    "$$ L2(\\Theta) = \\alpha \\sum_{\\substack{1<=i<n}} \\sum_{\\substack{0<=k<K}} \\theta_{i,k}^2 $$ \n",
    "\n",
    "avec:\n",
    "\n",
    "* $\\alpha$ le coefficient de régularisation\n",
    "\n",
    "**Remarque:** La première somme ne commence pas à 0 mais à 1 parce qu'on ne régularise pas les poids associés à la colonne de biais de X.\n",
    "\n",
    "Le fait d'ajouter ce terme conduit le modèle à apprendre les données tout en gardant ses poids le plus petit possible.\n",
    "\n",
    "\n",
    "\n",
    "#### Question 8 (1 point)\n",
    "Modifiez les fonctions  **_get_gradient** et **_cost_function** pour prendre en compte la régularisation lorsque le booléen self.regularization est vrai  dans SoftmaxClassifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9 (1 point)\n",
    "\n",
    "Le terme de régularisation est utilisé uniquement pendant l'entraînement. Quand on veut évaluer la performance du modèle **après entrainement**, on utilise la fonction de coût **non-régulée**.\n",
    "\n",
    "Implémentez la fonction **score** qui permet d'évaluer la qualité de la prédiction **après entrainement** dans SoftmaxClassifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping\n",
    "\n",
    "Un trop grand nombre d'**epoch** peut résulter en **overfitting**.\n",
    "Pour pallier à ce problème, on peut utiliser le mécanisme d'**early stopping**.\n",
    "Il s'agit d'arrêter l'entraînement si la différence de la fonction de coût entre deux **epochs consécutives** est inférieure à un **seuil**.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Question 10 (1 point)\n",
    "\n",
    "Finissez d'implémenter la fonction **fit** en y ajoutant le mécanisme d'**early stopping**  quand le booléen **self.early_stopping** est vrai le seuil est donné par la variable **self.threshold**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test de la solution:\n",
    "\n",
    "Le code ci-dessous importe le dataset de classification multiclasse **iris** disponible sur sklearn. Les données sont divisées en deux parties, l'ensemble d'entraînement et l'ensemble de test, puis elles sont normalisées.\n",
    "\n",
    "Le classifier implémenté dans le fichier **SoftmaxClassifier.py** est importé puis entrainé sur l'ensemble d'entrainement et testé sur l'ensemble de test.\n",
    "\n",
    "Le but de cette partie est juste de vérifier votre implémentation **quand vous êtes sûrs que votre code fonctionne**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load dataset\n",
    "data,target =load_iris().data,load_iris().target\n",
    "\n",
    "# split data in train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split( data, target, test_size=0.33, random_state=42)\n",
    "\n",
    "# standardize columns using normal distribution\n",
    "# fit on X_train and not on X_test to avoid Data Leakage\n",
    "s = StandardScaler()\n",
    "X_train = s.fit_transform(X_train)\n",
    "X_test = s.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SoftmaxClassifier import SoftmaxClassifier\n",
    "\n",
    "# import the custom classifier\n",
    "cl = SoftmaxClassifier()\n",
    "\n",
    "# train on X_train and not on X_test to avoid overfitting\n",
    "train_p = cl.fit_predict(X_train,y_train)\n",
    "test_p = cl.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous obtenez des valeurs relativement proches pour l'ensemble de test et d'entrainement, et qu'elles sont au moins supérieures à 0.8, votre modèle devrait être correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : (0.8952702702702703, 0.8941176470588236, 0.8936304393525333, None)\n",
      "test : (0.8985507246376812, 0.8444444444444444, 0.8387216648086214, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# display precision, recall and f1-score on train/test set\n",
    "print(\"train : \"+ str(precision_recall_fscore_support(y_train, train_p,average = \"macro\")))\n",
    "print(\"test : \"+ str(precision_recall_fscore_support(y_test, test_p,average = \"macro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(cl.losses_)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preprocessing (8 points)\n",
    "\n",
    "##  Kaggle \n",
    "Kaggle est un site dédié au machine learning. On y retrouve un grand nombre de dataset.\n",
    "Des compétitions sont organisées par des organisations. Ces dernières fournissent un dataset et un objectif. Les \"kagglers\" qui participent à ces compétitions soumettent leurs résultats en ligne. Il y a souvent des prix ou des emplois pour ceux qui obtiennent les meilleurs résultats.\n",
    "\n",
    "Il s'agit d'un bon moyen pour développer ses compétences en machine learning sur des vrais datasets.\n",
    "\n",
    "Vous pouvez créer un compte si vous voulez comparer vos résultats à ceux déjà en ligne pour la dataset que nous allons étudier.\n",
    "\n",
    "Vous pouvez créer un compte ici: https://www.kaggle.com/\n",
    "\n",
    "\n",
    "## Austin Animal Center Shelter Animal Outcomes dataset\n",
    "Le dataset que nous utiliserons est le \"Animal Outcomes dataset\" disponible à l'adresse suivante: https://www.kaggle.com/c/shelter-animal-outcomes.\n",
    "\n",
    "Il s'agit d'un problème de **classification multiclasse** des animaux sont recueillis dans un refuge après avoir été abandonnés, le but est de prédire la manière dont ils vont \"quitter \" le lieu:\n",
    "* Adoption\n",
    "* Retour au propriétaire\n",
    "* Décès \n",
    "* Euthanasie\n",
    "* Transfert à un autre centre\n",
    "\n",
    "Pour plus d'informations sur les données, rendez-vous sur kaggle.\n",
    "\n",
    "## Déroulement d'un projet de machine learning\n",
    "\n",
    "Le but de la suite de ce TP est de vous faire étudier une version simplifiée d'un projet complet de machine learning:\n",
    "\n",
    "1. Nettoyage des données, traitement des valeurs manquantes\n",
    "2. Mise en forme des données pour pouvoir les utiliser dans les algorithmes de machine learning\n",
    "3. Feature engineering: transformation ou combinaison de features entre elles\n",
    "4. Comparaison des performances des différents choix effectués lors du traîtement des données\n",
    "5. Comparaison des performances de différents modèles (dont celui implémenté en première partie)\n",
    "6. Optimisation des hyper-paramètres\n",
    "\n",
    "## Scikit-learn\n",
    "http://scikit-learn.org/stable/\n",
    "\n",
    "Il s'agit d'une bibliothèque de machine learning et data mining, elle propose des outils pour l'analyse et le traîtement des données,  des algorithmes classiques de machine learning comme les réseaux de neuronnes, la régression logistique, les SVM ou autre, enfin des outils permettant de comparer les modèles entre eux comme la cross validation.\n",
    "\n",
    "## Pandas\n",
    "\n",
    "Une bibliothèque permettant de stocker des données et de les manipuler facilement\n",
    "\n",
    "Les deux éléments de base de pandas sont le dataframe et la serie.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.html\n",
    "\n",
    "## Data processing tutorial\n",
    "\n",
    "**Avant de continuer le TP**, familiarisez-vous avec le **pré-traitement des données**, **pandas** et **scikit-learn**, un tutoriel est disponible dans le fichier: **data_processing_tutorial.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "#### Chargement de l'ensemble d'entraînement et de l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PATH = \"data/\"\n",
    "X_train = pd.read_csv(PATH + \"train.csv\")\n",
    "X_test = pd.read_csv(PATH + \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppression de colonnes inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns = [\"OutcomeSubtype\",\"AnimalID\"])\n",
    "X_test = X_test.drop(columns = [\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_train.drop(columns = [\"OutcomeType\"]),X_train[\"OutcomeType\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 premiers exemples de l'ensemble d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>SexuponOutcome</th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hambone</td>\n",
       "      <td>2014-02-12 18:22:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Shetland Sheepdog Mix</td>\n",
       "      <td>Brown/White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emily</td>\n",
       "      <td>2013-10-13 12:44:00</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Cream Tabby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pearce</td>\n",
       "      <td>2015-01-31 12:28:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Pit Bull Mix</td>\n",
       "      <td>Blue/White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-07-11 19:09:00</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>3 weeks</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Blue Cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-11-15 12:52:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Lhasa Apso/Miniature Poodle</td>\n",
       "      <td>Tan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name             DateTime AnimalType SexuponOutcome AgeuponOutcome  \\\n",
       "0  Hambone  2014-02-12 18:22:00        Dog  Neutered Male         1 year   \n",
       "1    Emily  2013-10-13 12:44:00        Cat  Spayed Female         1 year   \n",
       "2   Pearce  2015-01-31 12:28:00        Dog  Neutered Male        2 years   \n",
       "3      NaN  2014-07-11 19:09:00        Cat    Intact Male        3 weeks   \n",
       "4      NaN  2013-11-15 12:52:00        Dog  Neutered Male        2 years   \n",
       "\n",
       "                         Breed        Color  \n",
       "0        Shetland Sheepdog Mix  Brown/White  \n",
       "1       Domestic Shorthair Mix  Cream Tabby  \n",
       "2                 Pit Bull Mix   Blue/White  \n",
       "3       Domestic Shorthair Mix   Blue Cream  \n",
       "4  Lhasa Apso/Miniature Poodle          Tan  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 premiers exemples de l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>SexuponOutcome</th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summer</td>\n",
       "      <td>2015-10-12 12:15:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>10 months</td>\n",
       "      <td>Labrador Retriever Mix</td>\n",
       "      <td>Red/White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cheyenne</td>\n",
       "      <td>2014-07-26 17:59:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>2 years</td>\n",
       "      <td>German Shepherd/Siberian Husky</td>\n",
       "      <td>Black/Tan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gus</td>\n",
       "      <td>2016-01-13 12:20:00</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Brown Tabby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pongo</td>\n",
       "      <td>2013-12-28 18:12:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>4 months</td>\n",
       "      <td>Collie Smooth Mix</td>\n",
       "      <td>Tricolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skooter</td>\n",
       "      <td>2015-09-24 17:59:00</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Miniature Poodle Mix</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name             DateTime AnimalType SexuponOutcome AgeuponOutcome  \\\n",
       "0    Summer  2015-10-12 12:15:00        Dog  Intact Female      10 months   \n",
       "1  Cheyenne  2014-07-26 17:59:00        Dog  Spayed Female        2 years   \n",
       "2       Gus  2016-01-13 12:20:00        Cat  Neutered Male         1 year   \n",
       "3     Pongo  2013-12-28 18:12:00        Dog    Intact Male       4 months   \n",
       "4   Skooter  2015-09-24 17:59:00        Dog  Neutered Male        2 years   \n",
       "\n",
       "                            Breed        Color  \n",
       "0          Labrador Retriever Mix    Red/White  \n",
       "1  German Shepherd/Siberian Husky    Black/Tan  \n",
       "2          Domestic Shorthair Mix  Brown Tabby  \n",
       "3               Collie Smooth Mix     Tricolor  \n",
       "4            Miniature Poodle Mix        White  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 premiers exemples de l'attribut à prédire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Return_to_owner\n",
       "1         Euthanasia\n",
       "2           Adoption\n",
       "3           Transfer\n",
       "4           Transfer\n",
       "Name: OutcomeType, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travail demandé\n",
    "\n",
    "Pour vous faire gagner du temps, une partie des colonnes (Name,DateTime,color) ont déjà été traitées.\n",
    "\n",
    "\n",
    "En vous appuyant sur le tutoriel fourni, vous devez écrire un pipeline complet de transformation pour chacune des colonnes restantes du dataset (AgeuponOutcome,AnimalType,SexuponOutcome, Breed).\n",
    "\n",
    "Vous êtes **libres** de vos choix, mais vous devez les **justifer** colonne par colonne.\n",
    "Par exemple, vous pouvez choisir de combiner des colonnes entre elles, de séparer une colonne en plusieurs ou encore d'éliminer complètement une colonne si vous le justifiez correctement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La partie déjà prétraitée du dataset est chargée dans **X_train1** et **X_test1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = pd.read_csv(\"data/train_preprocessed.csv\")\n",
    "X_test1 = pd.read_csv(\"data/test_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color</th>\n",
       "      <th>HasName</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.973624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.421532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.973624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.471381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.868974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Color  HasName  Month  Day  Hour\n",
       "0  0.973624      1.0    2.0  1.0   3.0\n",
       "1 -1.421532      1.0   10.0  1.0   2.0\n",
       "2  0.973624      1.0    1.0  3.0   2.0\n",
       "3 -1.471381      0.0    7.0  1.0   3.0\n",
       "4 -0.868974      0.0   11.0  1.0   2.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le reste du dataset que vous devez traiter est:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns = [\"Color\",\"Name\",\"DateTime\"])\n",
    "X_test = X_test.drop(columns = [\"Color\",\"Name\",\"DateTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>SexuponOutcome</th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>Breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Shetland Sheepdog Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Pit Bull Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>3 weeks</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Lhasa Apso/Miniature Poodle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>1 month</td>\n",
       "      <td>Cairn Terrier/Chihuahua Shorthair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>3 weeks</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cat</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3 weeks</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>5 months</td>\n",
       "      <td>American Pit Bull Terrier Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Cairn Terrier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AnimalType SexuponOutcome AgeuponOutcome                              Breed\n",
       "0        Dog  Neutered Male         1 year              Shetland Sheepdog Mix\n",
       "1        Cat  Spayed Female         1 year             Domestic Shorthair Mix\n",
       "2        Dog  Neutered Male        2 years                       Pit Bull Mix\n",
       "3        Cat    Intact Male        3 weeks             Domestic Shorthair Mix\n",
       "4        Dog  Neutered Male        2 years        Lhasa Apso/Miniature Poodle\n",
       "5        Dog  Intact Female        1 month  Cairn Terrier/Chihuahua Shorthair\n",
       "6        Cat    Intact Male        3 weeks             Domestic Shorthair Mix\n",
       "7        Cat        Unknown        3 weeks             Domestic Shorthair Mix\n",
       "8        Dog  Spayed Female       5 months      American Pit Bull Terrier Mix\n",
       "9        Dog  Spayed Female         1 year                      Cairn Terrier"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26729 entries, 0 to 26728\n",
      "Data columns (total 4 columns):\n",
      "AnimalType        26729 non-null object\n",
      "SexuponOutcome    26728 non-null object\n",
      "AgeuponOutcome    26711 non-null object\n",
      "Breed             26729 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 835.4+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1 year      3969\n",
       "2 years     3742\n",
       "2 months    3397\n",
       "3 years     1823\n",
       "1 month     1281\n",
       "3 months    1277\n",
       "4 years     1071\n",
       "5 years      992\n",
       "4 months     888\n",
       "6 years      670\n",
       "Name: AgeuponOutcome, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train[\"AgeuponOutcome\"].value_counts())[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Question 11: AgeuponOutcome (1 point)\n",
    "    Pour la colonne AgeuponOutcome, nous allons transformer les données de façon à ce qu'elle soit toutes représentées sous la même forme. En les observant on peut voir que la plus petite unité est sous forme de jours, nous allons donc convertir toutes les valeurs de semaines, mois et années en jours. \n",
    "    1 semaine = 7 jours\n",
    "    1 mois    = 30.4375 jours (365.25 / 12)\n",
    "    1 année   = 365.25 jours\n",
    "\n",
    "    Nous savons aussi que 18 entrées ont cette valeur nulle. Dans ces cas, nous allons attribuer à l'entrée la moyenne des âges.\n",
    "    \n",
    "    22 entrées dans le training set ont la valeur 0 years. Nous allons laisser le pipeline l'interpréter comme 0 jours, mais cela n'est peut-être pas représentatif de la réalité.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dog    0.583449\n",
       "Cat    0.416551\n",
       "Name: AnimalType, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train[\"AnimalType\"].value_counts()/len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 12: AnimalType (1 point)\n",
    "\n",
    "    Pour cette colonne, il ne semble y avoir que 2 choix: dog ou cat. Il sera donc possible de la transformer en une seule colonne avec les seules valeurs possibles étant 0 ou 1, correspondant respectivement dog ou cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AnimalType</th>\n",
       "      <th>SexuponOutcome</th>\n",
       "      <th>AgeuponOutcome</th>\n",
       "      <th>Breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Shetland Sheepdog Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Pit Bull Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>3 weeks</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>2 years</td>\n",
       "      <td>Lhasa Apso/Miniature Poodle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Female</td>\n",
       "      <td>1 month</td>\n",
       "      <td>Cairn Terrier/Chihuahua Shorthair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>3 weeks</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cat</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3 weeks</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>5 months</td>\n",
       "      <td>American Pit Bull Terrier Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Spayed Female</td>\n",
       "      <td>1 year</td>\n",
       "      <td>Cairn Terrier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AnimalType SexuponOutcome AgeuponOutcome                              Breed\n",
       "0        Dog  Neutered Male         1 year              Shetland Sheepdog Mix\n",
       "1        Cat  Spayed Female         1 year             Domestic Shorthair Mix\n",
       "2        Dog  Neutered Male        2 years                       Pit Bull Mix\n",
       "3        Cat    Intact Male        3 weeks             Domestic Shorthair Mix\n",
       "4        Dog  Neutered Male        2 years        Lhasa Apso/Miniature Poodle\n",
       "5        Dog  Intact Female        1 month  Cairn Terrier/Chihuahua Shorthair\n",
       "6        Cat    Intact Male        3 weeks             Domestic Shorthair Mix\n",
       "7        Cat        Unknown        3 weeks             Domestic Shorthair Mix\n",
       "8        Dog  Spayed Female       5 months      American Pit Bull Terrier Mix\n",
       "9        Dog  Spayed Female         1 year                      Cairn Terrier"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 13: SexuponOutcome (1 point)\n",
    "\n",
    "    Cette colonne comprend en fait 2 informations: le sexe et la stérilité. Nous allons alors la séparer en plusieurs colonnes: male, femelle, stérile, pas stérile, et unknown. Chacune des colonnes aura la valeur 1 si nous avons la certitude que c'est le cas, 0 sinon. Ainsi, pour le cas où les animaux ont la valeur unknown, il suffira de mettre toutes les valeurs à 0 pour les 4 premières colonnes, au lieu de devoir choisir une valeur par défaut. Si la valeur est nulle, l'entrée sera traitée de la même façon que si elle avait la valeur unkown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutered Male    0.365857\n",
       "Spayed Female    0.329979\n",
       "Intact Male      0.131879\n",
       "Intact Female    0.131355\n",
       "Unknown          0.040892\n",
       "Name: SexuponOutcome, dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train[\"SexuponOutcome\"].value_counts()/len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 14: Breed (1 point)\n",
    "\n",
    "    La colonne breed est la plus difficile à traiter, puisque qu'il y a 1380 valeurs différentes dans le traning set. De plus, il faut gérer la notion de mix et de branches de races. \n",
    "    Nous allons traiter cette colonne comme suit: une nouvelle colonne sera créée pour chaque mot détecté dans la valeur de chaque entrée. Par contre, avant de faire cela, nous allons remplacer tous les caractères '/' par la string \" Mix \". Cela permettra par la suite au programme de considérer tous les mix comme étant un mix et de pouvoir attribuer la valeur 1 dans la colonne mix. \n",
    "    Pour ce qui est du reste des colonnes, toutes les races auront une ou plusieurs colonnes (ex Pit Bull aura les colonnes Pit et Bull). Le traitement des adjectifs ou autre information comme miniature et shorthair permettra d'automatiquement créer une colonne supplémentaire aux informations qui se retrouve dans les valeurs de la colonne breed.\n",
    "    Toutes les colonnes générées contiendront la valeur 1 si le mot se retrouve dans l'entrée et 0 sinon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "**Question 15: Complétez pipeline ci-dessous (4 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import TransformationWrapper\n",
    "from preprocessing import LabelEncoderP\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def GetAgeInDays(text):\n",
    "    DAYS_IN_YEAR = 365.25\n",
    "    MONTHS_IN_YEAR = 12\n",
    "    DAYS_IN_WEEK = 7\n",
    "    \n",
    "    #missing value\n",
    "    if text == 'x':\n",
    "        return -1\n",
    "\n",
    "    age_text_array = text.split(' ')\n",
    "    # text is '# unit' like '1 year' or '3 months'\n",
    "    value = int(age_text_array[0])\n",
    "    unit = age_text_array[1]\n",
    "    multiplier = 0\n",
    "    if unit == 'year' or unit == 'years':\n",
    "        multiplier = DAYS_IN_YEAR\n",
    "    elif unit == 'month' or unit == 'months':\n",
    "        multiplier = DAYS_IN_YEAR / MONTHS_IN_YEAR\n",
    "    elif unit == 'week' or unit == 'weeks':\n",
    "        multiplier = DAYS_IN_WEEK\n",
    "\n",
    "    value_in_days = value * multiplier\n",
    "\n",
    "    return value_in_days\n",
    "    \n",
    "\n",
    "#AgeuponOutcome\n",
    "pipeline_age = Pipeline([\n",
    "    (\"xFill\", SimpleImputer(strategy = 'constant', fill_value = 'x')),\n",
    "    (\"transform\", TransformationWrapper(transformation = GetAgeInDays)),\n",
    "    (\"meanFill\", SimpleImputer(missing_values = -1, strategy = 'mean')),\n",
    "])\n",
    "\n",
    "#AnimalType\n",
    "pipeline_animal_type = Pipeline([\n",
    "    (\"AnimalType\", OneHotEncoder(categories = 'auto', sparse = False))\n",
    "])\n",
    "\n",
    "def parse_sex(text):\n",
    "    if text == \"Unknown\":\n",
    "        return text\n",
    "    _, sex= text.split(\" \")\n",
    "    return sex\n",
    "\n",
    "def parse_status(text):\n",
    "    if text == \"Unknown\":\n",
    "        return text\n",
    "    status, _ = text.split(\" \")\n",
    "    if status == \"Spayed\" or status == \"Neutered\":\n",
    "        return \"Sterilized\"\n",
    "    else:\n",
    "        return \"Intact\"\n",
    "\n",
    "pipeline_sex = Pipeline([\n",
    "    (\"Sex\", TransformationWrapper(transformation = parse_sex)),\n",
    "    (\"encode\", OneHotEncoder(categories = 'auto', sparse = False))\n",
    "])\n",
    "\n",
    "pipeline_status = Pipeline([\n",
    "    (\"Status\", TransformationWrapper(transformation = parse_status)),\n",
    "    (\"encode\", OneHotEncoder(categories = 'auto', sparse = False))\n",
    "])\n",
    "\n",
    "#SexuponOutcome\n",
    "pipeline_sex_status = Pipeline([\n",
    "    (\"SexuponOutcome\", SimpleImputer(strategy = 'constant', fill_value = \"Unknown\")),\n",
    "    ('feats', FeatureUnion([\n",
    "        (\"Sex\", pipeline_sex), \n",
    "        (\"Status\", pipeline_status) \n",
    "    ]))\n",
    "])\n",
    "\n",
    "#Breed\n",
    "pipeline_breed = Pipeline([\n",
    "    (\"encode\", OneHotEncoder(categories = 'auto', sparse = False))\n",
    "])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"AnimalType\", pipeline_animal_type, [\"AnimalType\"]),\n",
    "    (\"AgeuponOutcome\", pipeline_age, [\"AgeuponOutcome\"]),\n",
    "    (\"SexuponOutcome\", pipeline_sex_status, [\"SexuponOutcome\"]),\n",
    "    (\"Breed\", pipeline_breed, [\"Breed\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lancez le pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = [\"cat\",\"dog\",\"age\",\"female\",\"male\",\"unknownSex\",\"sterilized\",\"intact\",\"unknownStatus\"]\n",
    "train_races_columns = [\"race\" + str(i) for i in range(len(columns), len(X_train.columns)) ]\n",
    "\n",
    "test_columns = [\"cat\",\"dog\",\"age\",\"female\",\"male\",\"unknownSex\",\"sterilized\",\"intact\",\"unknownStatus\"]\n",
    "test_races_columns = [\"race\" + str(i) for i in range(len(columns), len(X_train_prepared.columns)) ]\n",
    "\n",
    "X_train_prepared = pd.DataFrame(full_pipeline.fit_transform(X_train))\n",
    "X_test_prepared = pd.DataFrame(full_pipeline.fit_transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concaténation des deux parties du dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color</th>\n",
       "      <th>HasName</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>1379</th>\n",
       "      <th>1380</th>\n",
       "      <th>1381</th>\n",
       "      <th>1382</th>\n",
       "      <th>1383</th>\n",
       "      <th>1384</th>\n",
       "      <th>1385</th>\n",
       "      <th>1386</th>\n",
       "      <th>1387</th>\n",
       "      <th>1388</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.973624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.421532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.973624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>730.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.471381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.868974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>730.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Color  HasName  Month  Day  Hour    0    1       2    3    4  ...   \\\n",
       "0  0.973624      1.0    2.0  1.0   3.0  0.0  1.0  365.25  0.0  1.0  ...    \n",
       "1 -1.421532      1.0   10.0  1.0   2.0  1.0  0.0  365.25  1.0  0.0  ...    \n",
       "2  0.973624      1.0    1.0  3.0   2.0  0.0  1.0  730.50  0.0  1.0  ...    \n",
       "3 -1.471381      0.0    7.0  1.0   3.0  1.0  0.0   21.00  0.0  1.0  ...    \n",
       "4 -0.868974      0.0   11.0  1.0   2.0  0.0  1.0  730.50  0.0  1.0  ...    \n",
       "\n",
       "   1379  1380  1381  1382  1383  1384  1385  1386  1387  1388  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1394 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.concat([X_train1,X_train_prepared], axis = 1)\n",
    "X_test = pd.concat([X_test1,X_test_prepared], axis = 1)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1379</th>\n",
       "      <th>1380</th>\n",
       "      <th>1381</th>\n",
       "      <th>1382</th>\n",
       "      <th>1383</th>\n",
       "      <th>1384</th>\n",
       "      <th>1385</th>\n",
       "      <th>1386</th>\n",
       "      <th>1387</th>\n",
       "      <th>1388</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>730.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>730.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1389 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1       2     3     4     5     6     7     8     9     ...   1379  \\\n",
       "0   0.0   1.0  365.25   0.0   1.0   0.0   0.0   1.0   0.0   0.0  ...    0.0   \n",
       "1   1.0   0.0  365.25   1.0   0.0   0.0   0.0   1.0   0.0   0.0  ...    0.0   \n",
       "2   0.0   1.0  730.50   0.0   1.0   0.0   0.0   1.0   0.0   0.0  ...    0.0   \n",
       "3   1.0   0.0   21.00   0.0   1.0   0.0   1.0   0.0   0.0   0.0  ...    0.0   \n",
       "4   0.0   1.0  730.50   0.0   1.0   0.0   0.0   1.0   0.0   0.0  ...    0.0   \n",
       "\n",
       "   1380  1381  1382  1383  1384  1385  1386  1387  1388  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1389 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prepared.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model selection (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encodage de la classe cible sous forme d'entiers pour l'utiliser\n",
    "avec les algorithmes de scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adoption' 'Died' 'Euthanasia' 'Return_to_owner' 'Transfer']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "target_label = LabelEncoder()\n",
    "y_train_label = target_label.fit_transform(y_train)\n",
    "print(target_label.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble de validation\n",
    "Pour comparer différents modèles entre eux, on ne peut pas utiliser\n",
    "l'ensemble de test, sinon on serait tenté de garder le modèle correspondant le mieux à l'ensemble de test ce qui pourrait conduire à l'overfitting.\n",
    "\n",
    "Il est d'usage de créer un nouvel ensemble de la taille de l'ensemble de test, l'ensemble de **validation**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "La cross-validation est une méthode utile pour comparer la performance de différents modèles de machine learning **sans créer d'ensemble de validation**.\n",
    "\n",
    "Il existe différents types de cross-validation, la procédure la plus classique est la suivante:\n",
    "* Diviser aléatoirement l'ensemble d'entraînement en deux parties (90%/10% par exemple).\n",
    "* Entraîner le modèle sur la plus grande partie, et le tester sur l'autre partie.\n",
    "* Recommencer n fois\n",
    "* Calculer la moyenne et l'écart type des résultats\n",
    "\n",
    "Les avantages sont les suivants:\n",
    "* Considérer la totalité de l'ensemble d'entraînement pour l'évaluation (sans se priver de l'ensemble de validation)\n",
    "* Obtenir l'écart-type des résultats permet une meilleure évaluation de la précision du modèle.\n",
    "\n",
    "L'inconvénient principal est le temps de calcul, étant donné que l'on effectue l'apprentissage du modèle plusieurs fois, cette méthode peut être impossible pour des datasets contenant un grand nombre d'exemple (> 10e5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 2: StratifiedKFold (1 point)\n",
    "\n",
    "En observant la distribution des classes de l'attribut cible (à l'aide des fonctions de visualisation de pandas), justifiez l'utilisation de l'objet **StratifiedKFold** de sklearn pour la division de l'ensemble d'entraînement lors de cross-validation en comparaison à une méthode pûrement **aléatoire**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adoption           10769\n",
       "Transfer            9422\n",
       "Return_to_owner     4786\n",
       "Euthanasia          1555\n",
       "Died                 197\n",
       "Name: OutcomeType, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Comme on peut le constater avec la fonction de visualisation value_counts, le nombre de cas dans chaque classe est \n",
    "    très différent. En effet, on remarque que le nombre d'animaux morts n'est que de 197, alors que le nombre d'animaux \n",
    "    adoptés est de plus de 10000. Cela veut dire que si l'on utilisait une méthode de cross-validation pûrement aléatoire,\n",
    "    il y a de forte chance que la partie de test n'ait pas ou très peu de cas avec un animal mort. On ne teste donc pas\n",
    "    complètement le comportement du modèle. L'utilisation de StratifiedKFold permet à chaque division de l'ensemble de \n",
    "    garder une certaine proportion minimale pour chaque classe, et ainsi s'assurer de tester toutes les classes lors de\n",
    "    la phase de test.\n",
    "'''\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 16: (1 point)\n",
    "\n",
    "\n",
    "**Choisir au moins deux modèles permettant la classification multiclasse sur sklearn en plus du modèle implémenté dans la première partie du TP**.\n",
    "\n",
    "**Complétez la fonction compare qui effectue la crossvalidation pour différents modèles et différentes métriques, et renvoie la liste des moyennes et écart-types pour chacune des métriques, pour chacun des modèles. **\n",
    "\n",
    "**En vous basant sur les différentes métriques, concluez quant au modèle le plus performant.**\n",
    "\n",
    "Evaluez les modèles pour les différentes métriques proposées:\n",
    "* **log loss**: c'est la métrique d'évaluation de kaggle\n",
    "* **precision**: correspond à la qualité de la prédiction, le nombre de classes correctement prédites par le nombre de prédiction total\n",
    "* **recall**: le nombre d'éléments appartenant à une classe, identifiés comme tel, divisé par le nombre total des éléments de cette classe.\n",
    "* **f-score**: une moyenne de la precision et du recall\n",
    "\n",
    "**Remarque: precision et recall sont deux mesures complémentaires pour l'évaluation d'un modèle de classification multi-classe.**\n",
    "\n",
    "Dans le cas d'une classification binaire avec un déséquilibre de la classe cible important, (90%/10%), en évaluant le résultat de la classification avec l'accuracy (nombre de prédictions correctes divisé par le nombre de prédictions total), on peut obtenir un très bon score (90% d'accuracy) en choisissant de prédire systématiquement la classe majoritaire.\n",
    "\n",
    "Dans un tel cas, la precision serait élevée de même, mais le recall serait très bas , nous indiquant la médiocrité de notre modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def compare(models,X_train,y_train,nb_runs, scoring):\n",
    "    losses = []\n",
    "    \n",
    "    for m in models:\n",
    "        losses.append(cross_validate(m, X_train, y_train, scoring=scoring, cv = nb_run, return_train_score=False))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabrice/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/fabrice/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/fabrice/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'fit_time': array([2.89408851, 2.80635476, 2.6691339 ]),\n",
       "  'score_time': array([0.32595205, 0.33090043, 0.32939982]),\n",
       "  'test_neg_log_loss': array([-3.25996509, -3.28300108, -3.13218387]),\n",
       "  'test_precision_macro': array([0.45320164, 0.47701354, 0.45184195]),\n",
       "  'test_recall_macro': array([0.39888201, 0.41591187, 0.39772386]),\n",
       "  'test_f1_macro': array([0.41022315, 0.430891  , 0.40826253])},\n",
       " {'fit_time': array([4.68194866, 4.68640399, 4.71278024]),\n",
       "  'score_time': array([1.17461371, 1.17095685, 1.18079185]),\n",
       "  'test_neg_log_loss': array([-1.54866804, -1.54650277, -1.54782669]),\n",
       "  'test_precision_macro': array([0.44754547, 0.43525261, 0.45960398]),\n",
       "  'test_recall_macro': array([0.39282367, 0.37416466, 0.42081173]),\n",
       "  'test_f1_macro': array([0.40146809, 0.37765818, 0.42640017])},\n",
       " {'fit_time': array([0.95279145, 1.02331448, 0.96559215]),\n",
       "  'score_time': array([0.13523769, 0.13540339, 0.13418531]),\n",
       "  'test_neg_log_loss': array([-13.82972193, -14.18098188, -13.86798797]),\n",
       "  'test_precision_macro': array([0.42248783, 0.41759136, 0.42838458]),\n",
       "  'test_recall_macro': array([0.42052394, 0.4157925 , 0.42219188]),\n",
       "  'test_f1_macro': array([0.42108507, 0.41648644, 0.42482081])},\n",
       " {'fit_time': array([1.92534518, 1.90452075, 1.89428735]),\n",
       "  'score_time': array([74.89601159, 73.82835245, 74.91813302]),\n",
       "  'test_neg_log_loss': array([-4.79971939, -4.73519073, -4.85247414]),\n",
       "  'test_precision_macro': array([0.40041002, 0.38732306, 0.37874926]),\n",
       "  'test_recall_macro': array([0.36798363, 0.36590816, 0.35919152]),\n",
       "  'test_f1_macro': array([0.37176062, 0.36907903, 0.35990323])}]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from SoftmaxClassifier import SoftmaxClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "nb_run = 3\n",
    "\n",
    "models = [\n",
    "    #SoftmaxClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    KNeighborsClassifier()\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "scoring = ['neg_log_loss', 'precision_macro','recall_macro','f1_macro']\n",
    "\n",
    "compare(models,X_train,y_train_label,nb_run,scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tel qu'on peut le constater, le modèle qui semble être le plus prometteur en considérant le log_loss est le modèle AdaBoost. Par contre, on peut remarquer que ce n'est pas nécessairement le modèle qui prédit le mieux la classe. Le modèle RandomForest a donné une métrique de précision généralement légèrement supérieure à celle d'AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 17: Matrice de confusion (0.5 point)\n",
    "\n",
    "La matrice de confusion A est telle que $A_{i,j}$ correspond au nombre d'exemples de la classe i classifié comme appartenant à la classe j.\n",
    "\n",
    "Entrainez le modèle sélectionné sur la totalité de l'ensemble d'entraînement.\n",
    "A l'aide de la matrice de confusion et de la distribution des classes, analysez plus en détail les performances du modèle choisi et justifiez les."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train selected model\n",
    "\n",
    "selected_model = AdaBoostClassifier()\n",
    "selected_model.fit(X_train,y_train_label)\n",
    "y_pred = selected_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adoption</th>\n",
       "      <th>Died</th>\n",
       "      <th>Euthanasia</th>\n",
       "      <th>Return_to_owner</th>\n",
       "      <th>Transfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adoption</th>\n",
       "      <td>8778</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1043</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Died</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Euthanasia</th>\n",
       "      <td>192</td>\n",
       "      <td>9</td>\n",
       "      <td>203</td>\n",
       "      <td>306</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Return_to_owner</th>\n",
       "      <td>2490</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>1572</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transfer</th>\n",
       "      <td>2350</td>\n",
       "      <td>37</td>\n",
       "      <td>129</td>\n",
       "      <td>606</td>\n",
       "      <td>6300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Adoption  Died  Euthanasia  Return_to_owner  Transfer\n",
       "Adoption             8778     0           9             1043       939\n",
       "Died                   11     5           2               10       169\n",
       "Euthanasia            192     9         203              306       845\n",
       "Return_to_owner      2490     4          88             1572       632\n",
       "Transfer             2350    37         129              606      6300"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(y_train_label, y_pred), columns = target_label.classes_, index = target_label.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Distribution des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adoption' 'Died' 'Euthanasia' 'Return_to_owner' 'Transfer']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f51c92eadd8>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "print(target_label.classes_)\n",
    "pd.Series(y_train_label).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    On peut voir que le modèle prédit les classes avec sensiblement les même proportions que celles qui se retrouvent \n",
    "    pour les classes réelles dans le dataset. Le modèle a donc du sens de ce point de vue là.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 3: Optimisation des hyper-paramètres (1 point)\n",
    "\n",
    "Les hyper-paramètres sont les paramètres fixés avant la phase d'apprentissage. Pour optimiser les performances du modèle, on peut sélectionner les meilleurs hyper-paramètres.\n",
    "\n",
    "A l'aide de sklearn, optimisez les hyper-paramètres du modèle que vous avez sélectionné et montrez que les performances ont été améliorées.\n",
    "Vous pouvez utiliser par exemple: **GridSearchCV**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 18: Soumission (0.5 point)\n",
    "\n",
    "Enfin, effectuez la prédiction sur l'ensemble de test et joignez vos résultats au rendu du TP.\n",
    "\n",
    "**Optionnel**: Vous pouvez soumettre vos résultats sur kaggle et noter votre performance en terme de log loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = \n",
    "# pred_test = pd.Series(best_model.transform(X_test))\n",
    "# pred_test.to_csv(\"test_prediction.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
